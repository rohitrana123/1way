# ------------------------------------------------------------
# Mutual Information Feature Selection (Titanic dataset)
# Feature_engine version — fixed with y passed correctly
# ------------------------------------------------------------
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.feature_selection import mutual_info_classif, SelectKBest
from feature_engine.encoding import RareLabelEncoder, OrdinalEncoder

# Step 1 — Load dataset
variables = ['pclass', 'survived', 'sex', 'age', 'sibsp', 'parch', 'fare', 'cabin', 'embarked']
data = pd.read_csv('https://www.openml.org/data/get_csv/16826755/phpMYEkMl',
                   usecols=variables, na_values='?', dtype={'fare': float, 'age': float})
data.dropna(subset=['embarked', 'fare'], inplace=True)
data['age'] = data['age'].fillna(data['age'].mean())

# Step 2 — Simplify cabin info
def get_first_cabin(row):
    try:
        return row.split()[0]
    except:
        return 'N'
data['cabin'] = data['cabin'].apply(get_first_cabin).str[0]

# Step 3 — Encode rare labels
encoder = RareLabelEncoder(variables='cabin', n_categories=2)
data = encoder.fit_transform(data)

# Step 4 — Encode categorical variables (pass y to avoid ValueError)
y = data['survived']
ordinal_encoder = OrdinalEncoder(variables=['sex', 'embarked', 'cabin'])
data = ordinal_encoder.fit_transform(data, y)  # ✅ FIXED: y passed correctly

# Step 5 — Mutual Information feature selection
X = data.drop('survived', axis=1)
selector = SelectKBest(mutual_info_classif, k='all')
selector.fit(X, y)

scores = pd.Series(selector.scores_, index=X.columns).sort_values(ascending=False)
print("\nMutual Information Scores:\n", scores)

# Step 6 — Visualization
plt.figure(figsize=(8,5))
scores.plot(kind='bar', color='seagreen')
plt.title('Mutual Information Scores (Feature Importance)')
plt.ylabel('Mutual Information Value')
plt.xlabel('Features')
plt.show()
